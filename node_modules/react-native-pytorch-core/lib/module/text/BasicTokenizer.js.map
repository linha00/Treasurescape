{"version":3,"sources":["BasicTokenizer.ts"],"names":["BasicTokenizer","constructor","lowercase","neverSplit","Set","punctuations","tokenize","text","tokens","words","split","forEach","word","has","push","toLowerCase","i","length","j","slice"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAOA,OAAO,MAAMA,cAAN,CAAqB;AAK1B;AACF;AACA;AACA;AACA;AACEC,EAAAA,WAAW,CAAC;AAACC,IAAAA,SAAS,GAAG,IAAb;AAAmBC,IAAAA,UAAU,GAAG;AAAhC,GAAD,EAA4D;AAAA;;AAAA;;AAAA;;AACrE,SAAKA,UAAL,GAAkB,IAAIC,GAAJ,CAAQD,UAAR,CAAlB;AACA,SAAKD,SAAL,GAAiBA,SAAjB;AACA,SAAKG,YAAL,GAAoB,IAAID,GAAJ,CAAQ,CAC1B,GAD0B,EAE1B,GAF0B,EAG1B,GAH0B,EAI1B,GAJ0B,EAK1B,GAL0B,EAM1B,GAN0B,EAO1B,GAP0B,EAQ1B,GAR0B,EAS1B,GAT0B,EAU1B,GAV0B,EAW1B,GAX0B,EAY1B,GAZ0B,EAa1B,GAb0B,EAc1B,GAd0B,EAe1B,GAf0B,EAgB1B,GAhB0B,EAiB1B,GAjB0B,EAkB1B,GAlB0B,EAmB1B,GAnB0B,EAoB1B,GApB0B,EAqB1B,GArB0B,EAsB1B,GAtB0B,EAuB1B,GAvB0B,EAwB1B,IAxB0B,EAyB1B,GAzB0B,EA0B1B,GA1B0B,EA2B1B,GA3B0B,EA4B1B,GA5B0B,EA6B1B,GA7B0B,EA8B1B,GA9B0B,EA+B1B,GA/B0B,EAgC1B,GAhC0B,CAAR,CAApB;AAkCD;AAED;AACF;AACA;AACA;AACA;AACA;;;AACSE,EAAAA,QAAQ,CAACC,IAAD,EAAyB;AACtC,UAAMC,MAAgB,GAAG,EAAzB;AACA,UAAMC,KAAK,GAAGF,IAAI,CAACG,KAAL,CAAW,KAAX,CAAd;AACAD,IAAAA,KAAK,CAACE,OAAN,CAAcC,IAAI,IAAI;AACpB,UAAI,KAAKT,UAAL,CAAgBU,GAAhB,CAAoBD,IAApB,CAAJ,EAA+B;AAC7BJ,QAAAA,MAAM,CAACM,IAAP,CAAYF,IAAZ;AACA;AACD;;AACD,UAAI,KAAKV,SAAT,EAAoB;AAClBU,QAAAA,IAAI,GAAGA,IAAI,CAACG,WAAL,EAAP;AACD;;AACD,UAAIC,CAAC,GAAG,CAAR;;AACA,aAAOA,CAAC,GAAGJ,IAAI,CAACK,MAAhB,EAAwB;AACtB,YAAI,KAAKZ,YAAL,CAAkBQ,GAAlB,CAAsBD,IAAI,CAACI,CAAD,CAA1B,CAAJ,EAAoC;AAClCR,UAAAA,MAAM,CAACM,IAAP,CAAYF,IAAI,CAACI,CAAD,CAAhB;AACAA,UAAAA,CAAC,IAAI,CAAL;AACD,SAHD,MAGO;AACL,cAAIE,CAAC,GAAGF,CAAC,GAAG,CAAZ;;AACA,iBAAOE,CAAC,GAAGN,IAAI,CAACK,MAAT,IAAmB,CAAC,KAAKZ,YAAL,CAAkBQ,GAAlB,CAAsBD,IAAI,CAACM,CAAD,CAA1B,CAA3B,EAA2D;AACzDA,YAAAA,CAAC,IAAI,CAAL;AACD;;AACDV,UAAAA,MAAM,CAACM,IAAP,CAAYF,IAAI,CAACO,KAAL,CAAWH,CAAX,EAAcE,CAAd,CAAZ;AACAF,UAAAA,CAAC,GAAGE,CAAJ;AACD;AACF;AACF,KAtBD;AAuBA,WAAOV,MAAP;AACD;;AAlFyB","sourcesContent":["/**\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n * @format\n */\n\nexport type BasicTokenizerConfig = {\n  lowercase?: boolean;\n  neverSplit?: string[];\n};\n\nexport class BasicTokenizer {\n  private lowercase: boolean;\n  private neverSplit: Set<string>;\n  private punctuations: Set<string>;\n\n  /**\n   * Construct a BasicTokenizer Object.\n   *\n   * @param config A basic tokenizer configuration object that specifies the non-splitable symbol, lowercase, customized punctuations, etc.\n   */\n  constructor({lowercase = true, neverSplit = []}: BasicTokenizerConfig) {\n    this.neverSplit = new Set(neverSplit);\n    this.lowercase = lowercase;\n    this.punctuations = new Set([\n      '!',\n      '\"',\n      '#',\n      '$',\n      '%',\n      '&',\n      \"'\",\n      '(',\n      ')',\n      '*',\n      '+',\n      ',',\n      '-',\n      '.',\n      '/',\n      ':',\n      ';',\n      '<',\n      '=',\n      '>',\n      '?',\n      '@',\n      '[',\n      '\\\\',\n      ']',\n      '^',\n      '_',\n      '`',\n      '{',\n      '|',\n      '}',\n      '~',\n    ]);\n  }\n\n  /**\n   * Tokenize any text with basic operations like lowercase transform, blackspace trimming and punctuation splitting.\n   * Normally used to clean text before passing to other tokenizers (e.g. wordpiece).\n   *\n   * @param text The text to be processed\n   */\n  public tokenize(text: string): string[] {\n    const tokens: string[] = [];\n    const words = text.split(/\\s+/);\n    words.forEach(word => {\n      if (this.neverSplit.has(word)) {\n        tokens.push(word);\n        return;\n      }\n      if (this.lowercase) {\n        word = word.toLowerCase();\n      }\n      let i = 0;\n      while (i < word.length) {\n        if (this.punctuations.has(word[i])) {\n          tokens.push(word[i]);\n          i += 1;\n        } else {\n          let j = i + 1;\n          while (j < word.length && !this.punctuations.has(word[j])) {\n            j += 1;\n          }\n          tokens.push(word.slice(i, j));\n          i = j;\n        }\n      }\n    });\n    return tokens;\n  }\n}\n"]}